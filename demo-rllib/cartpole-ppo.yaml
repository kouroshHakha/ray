cartpole-ppo:
    env: CartPole-v1
    run: PPO
    stop:
        sampler_results/episode_reward_mean: 450
        timesteps_total: 100000
    config:
        # Works for both torch and tf.
        framework: torch
        gamma: 0.99
        lr: 0.0003
        train_batch_size: 4096
        sgd_minibatch_size: 64
        num_workers: 64
        observation_filter: MeanStdFilter
        num_sgd_iter: 6
        vf_loss_coeff: 0.01
        num_gpus: 1
        model:
            fcnet_hiddens: [32]
            fcnet_activation: linear
            vf_share_layers: true
        enable_connectors: true
