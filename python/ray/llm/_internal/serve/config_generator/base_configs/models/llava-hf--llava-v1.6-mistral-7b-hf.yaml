deployment_config:
  autoscaling_config:
    target_ongoing_requests: 4
  max_ongoing_requests: 8

model_loading_config:
  model_id: llava-hf/llava-v1.6-mistral-7b-hf

generation_config:
  prompt_format:
    system: "{instruction}" # not used for now
    assistant: "{instruction}" # not used for now
    trailing_assistant: ""
    user: "[INST] <image>\n{instruction} [/INST]"
    vision: true
  stopping_sequences: []
  stopping_tokens: []

llm_engine: VLLMEngine

engine_kwargs:
  trust_remote_code: true
  tokenizer_pool_size: 2
  tokenizer_pool_extra_config:
    runtime_env:
      pip: null

accelerator_type: A10G

lora_config: null
