deployment_config:
  autoscaling_config:
    target_ongoing_requests: 16
  max_ongoing_requests: 32

model_loading_config:
  model_id: mistralai/Mixtral-8x22B-Instruct-v0.1

generation:
  prompt_format:
    system: "{instruction}\n\n "
    assistant: "{instruction} </s> "
    trailing_assistant: ""
    user: "[INST] {system}{instruction} [/INST]"
    bos: "<s> "
    system_in_user: true
    system_in_last_user: true
    add_system_tags_even_if_message_is_empty: false
    strip_whitespace: true
    default_system_message: "Always assist with care, respect, and truth. Respond with utmost utility yet securely. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity."
  stopping_sequences: []
  stopping_tokens: []

llm_engine: VLLMEngine

engine_kwargs:
  trust_remote_code: true
  tokenizer_pool_size: 2
  tokenizer_pool_extra_config:
    runtime_env:
      pip: null
  tensor_parallel_size: 8

accelerator_type: A100_80G

lora_config: null
