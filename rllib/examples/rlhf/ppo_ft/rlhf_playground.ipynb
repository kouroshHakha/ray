{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: self_instruct/self_instruct\n",
      "Reusing dataset self_instruct (/home/ray/.cache/huggingface/datasets/yizhongw___self_instruct/self_instruct/1.0.0/11093735ceb03802310b2f412253585f7bd1cc0435787541e37d4d2b4cca4148)\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"yizhongw/self_instruct\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[25714,    25,  9938,   503,   644,   389,   262,  1994, 10233,\n",
       "          287,   262,  3188,    30,  5072,   366, 26652,   352,  1600,\n",
       "          366, 26652,   362,  1600,  2644,   837,   366, 26652,   299,\n",
       "         1911,   198,   198,   464,  1578,  1829,   468, 23019,   422,\n",
       "          262,  6342, 13963, 12729,    13,   628]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens = tokenizer(ds[1][\"prompt\"], return_tensors=\"np\")\n",
    "prompt_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gymnasium import spaces\n",
    "foo = spaces.Discrete(2).sample()\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 20:49:05.047088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ray/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-06 20:49:05.047184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ray/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-06 20:49:05.047191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from rllib.examples.rlhf.ppo_ft.rlhf_env import RLHFEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RLHFEnv({\n",
    "    \"tokenizer_path\": \"gpt2\",\n",
    "    \"sft_model_path\": \"gpt2\",\n",
    "    \"prompt_dataset_path\": \"yizhongw/self_instruct\",\n",
    "    \"prompt_dataset_split\": \"train\",\n",
    "    \"kl_coeff\": 0.2,\n",
    "    \"max_generation_length\": 50,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[15056,   281,  7177,   286, 37014,    11,  3551,   257,  2163,\n",
      "          326,  5860,  2081,   611,   612,  7160,   281,  6376,  1312,\n",
      "          884,   326,   790,  5002,   287,   262,  7177,   468,   663,\n",
      "         1988,  3220,   416,   530,   618,   356,  1445,   340,  2651,\n",
      "         1312,  4113,    13,   628]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset(seed=52)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15056,   281,  7177,   286, 37014,    11,  3551,   257,  2163,   326,\n",
       "          5860,  2081,   611,   612,  7160,   281,  6376,  1312,   884,   326,\n",
       "           790,  5002,   287,   262,  7177,   468,   663,  1988,  3220,   416,\n",
       "           530,   618,   356,  1445,   340,  2651,  1312,  4113,    13,   628]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.tensor(obs['input_ids'])\n",
    "attention_mask = torch.tensor(obs['attention_mask'])\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.examples.rlhf.ppo_ft.rlhf_env import generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "1 step took 9.378345012664795 seconds\n",
      "Reward: -2.2293795585632328\n",
      "{'n_response_tokens': 50, 'r_align': -1.0, 'r_kl': tensor(6.1469)}\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "obs, _ = env.reset(seed=62)\n",
    "out = generate_response(\n",
    "    model, \n",
    "    input_ids=torch.tensor(obs['input_ids']),\n",
    "    max_length=env.max_generation_length, \n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "n_generated_tokens = out[\"n_generated_tokens\"]\n",
    "n_input_tokens = out[\"n_input_tokens\"]\n",
    "generated_tokens = out[\"sequence\"][-n_generated_tokens:]\n",
    "action = {\n",
    "    \"input_ids\": generated_tokens.numpy(),\n",
    "    \"response_mask\": np.array([[0]*n_input_tokens + [1]*n_generated_tokens]),\n",
    "    \"probs\": out[\"probs\"].numpy(),\n",
    "    \"attention_mask\": np.array([[1]*(n_input_tokens + n_generated_tokens)]),\n",
    "}\n",
    "foo = env.step(action)\n",
    "reward = foo[1]\n",
    "print(f\"1 step took {time.time() - s} seconds\")\n",
    "print(f\"Reward: {reward}\")\n",
    "pprint(foo[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('attention_mask', [0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0]), ('input_ids', [23127, 47606, 43639, 5807, 16409, 27139, 4651, 13782, 57, 36042, 35282, 43280, 5909, 13918, 21517, 27746, 39205, 8260, 40020, 17163, 35755, 30626, 30811, 30446, 30153, 10247, 41597, 33842, 34697, 14624, 17691, 16673, 857, 22237, 38736, 8512, 34032, 9354, 20336, 37159, 47733, 31426, 14858, 31596, 4431, 20753, 42560, 32855, 10076, 27857, 17078, 705, 27491, 50197, 27960, 1595, 39935, 2470, 22441, 10829, 38825, 7493, 47848, 47383, 28443, 4423, 28620, 44838, 26009, 49730, 44335, 31325, 10852, 13070, 15086, 47388, 13167, 22780, 32733, 21856, 26238, 20879, 18406, 48000, 32664, 31789, 33390, 13182, 35868, 39989, 48624, 6839, 22780, 30454, 859, 31043, 49563, 27437, 37862, 15083, 41015, 36829, 15425, 30609, 43555, 25349, 36477, 12297, 37259, 43028, 48922, 48187, 8745, 3786, 49152, 29516, 7453, 46986, 19670, 7587, 50142, 41013, 19833, 42934, 43942, 34407, 30466, 41149, 3473, 34988, 6560, 35906, 12974, 12787, 3043, 18239, 27796, 15840, 15063, 13720, 37651, 3741, 23578, 31788, 17107, 30965, 44796, 23696, 18315, 8555, 31867, 32378, 23950, 13461, 11163, 27279, 43651, 19592, 42795, 41174, 27244, 30721, 29168, 46243, 9631, 5576, 12234, 30100, 28677, 37740, 25244, 21853, 22656, 30200, 20900, 34723, 48884, 36301, 32391, 43776, 37978, 32132, 33286, 44345, 16146, 47537, 7865, 43898, 4138, 46609, 1201, 17997, 6455, 31820, 45215, 30619, 9243, 16207, 20530, 19994, 1428, 13525, 21997, 8315, 7099, 28861, 1187, 42977, 37413, 31192, 6251, 4339, 36021, 22932, 42100, 36893, 6796, 23161, 41023, 3917, 6785, 25053, 23824, 25317, 37730, 36931, 26350, 44514, 3564, 42191, 15141, 32978, 39121, 5925, 7160, 49886, 19705, 42329, 19271, 46614, 50211, 50089, 29634, 42418, 46519, 24411, 10378, 38730, 30507, 32276, 9244, 18060, 17614, 48243, 19214, 29697, 22333, 31637, 6314, 29687, 40555, 2159, 42883, 31504, 32702, 28947, 4666, 1582, 1270, 49586, 26762, 27038, 18720, 31703, 35147, 17616, 31841, 13458, 11435, 4664, 1567, 27088, 1598, 27037, 23149, 27166, 41639, 35348, 4613, 16881, 18420, 1454, 24763, 46420, 26581, 2677, 11865, 27316, 5485, 438, 26823, 30672, 34181, 9150, 42591, 28929, 7706, 40481, 10854, 31136, 42887, 49450, 5129, 26123, 20521, 36484, 7866, 658, 4622, 35592, 37906, 47157, 48410, 26114, 16478, 41341, 34055, 33125, 21818, 12924, 14868, 77, 37636, 34967, 2098, 13126, 28601, 18661, 47265, 17045, 20010, 12595, 10510, 47316, 3626, 25305, 20617, 6252, 1534, 33735, 35567, 45979, 26875, 19712, 42556, 43833, 33810, 2042, 5433, 44807, 49471, 31404, 44887, 26996, 13212, 25900, 1665, 6873, 39756, 11323, 48521, 18146, 27357, 46490, 42563, 42647, 35860, 27010, 39455, 25757, 33300, 24000, 40078, 47487, 1655, 7642, 13247, 13238, 36973, 8252, 2263, 37027, 18450, 13774, 4255, 34193, 47265, 49, 21374, 20301, 36535, 5011, 19913, 28975, 37567, 17455, 14169, 19042, 49782, 23421, 36970, 46436, 46993, 43251, 6772, 37829, 34943, 25696, 46597, 37112, 10551, 18809, 19370, 2467, 31829, 41304, 32546, 9326, 14275, 9250, 41844, 3853, 41663, 17781, 775, 24941, 18234, 4460, 475, 34975, 15893, 4874, 6171, 50087, 22099, 8070, 27622, 48246, 32601, 28481, 49845, 34715, 18128, 41064, 27414, 31863, 29497, 49330, 46236, 29509, 33988, 8660, 32590, 18006, 33556, 25418, 12505, 33180, 49822, 49234, 50131, 30104, 37018, 23928, 49056, 35362, 41096, 44974, 13494, 48773, 20999, 25290, 12302, 22815, 28015, 2021, 15326, 20605, 18045, 5244, 22440, 48164, 28505, 19882, 5547, 2595, 40956, 6344, 38933, 18546, 2422, 18705, 3021, 29998, 23374, 29027, 14247, 5047, 11590, 3999, 1266, 35156, 8910, 40607, 34461, 46623, 30345, 9029, 46234, 48266, 33720, 15984, 21698, 48177, 8914, 24481, 12237, 41200, 45372, 28941, 26832, 38988, 31871, 6202, 2094, 45793, 3258, 42198, 44958, 18589, 12415, 21248, 29298, 35497, 40722, 35601, 19907, 32016, 24947, 42627, 10917, 31469, 3898, 14971, 36892, 15183, 10677, 46466, 8715, 11975, 22034, 3160, 20107, 37542, 29059, 27946, 20769, 29191, 2652, 19711, 3197, 16729, 25341, 32980, 6140, 45119, 925, 11291, 27220, 18422, 26574, 29125, 3526, 37045, 23094, 25463, 46766, 1193, 3837, 28271, 3792, 18843, 26371, 50164, 35, 34338, 31315, 20903, 19003, 9325, 3310, 14498, 29842, 29963, 39496, 6206, 21405, 49984, 49013, 50198, 4156, 1153, 33193, 23634, 22142, 29424, 5132, 16779, 28787, 35722, 11436, 27285, 43652, 29997, 15891, 12298, 41855, 7183, 42678, 44498, 30733, 30266, 48527, 8732, 11681, 27601, 36546, 7348, 16912, 40401, 14748, 32299, 30362, 46074, 40144, 17616, 33972, 11489, 23435, 21182, 3218, 15503, 34708, 48748, 2344, 12554, 23392, 47798, 6918, 41982, 44239, 22779, 47348, 39116, 45967, 43915, 34582, 44847, 29932, 8376, 16338, 46138, 6852, 48878, 39033, 21671, 16288, 26150, 22277, 20363, 45992, 31351, 22417, 22906, 31185, 45740, 1059, 8075, 26961, 35065, 41209, 2914, 37838, 39722, 8930, 39280, 44861, 10514, 6254, 43887, 9340, 29067, 50172, 26161, 49824, 3570, 49097, 17804, 964, 14705, 13525, 41709, 38095, 10571, 27023, 9515, 18278, 24844, 30536, 28729, 48719, 31016, 16349, 49502, 47552, 44635, 32890, 39606, 14972, 46027, 32995, 9677, 30638, 29438, 1064, 43479, 29520, 37965, 44075, 23445, 31371, 35280, 34570, 1765, 49561, 2952, 24113, 16832, 12595, 5712, 12966, 24177, 26049, 10905, 31991, 31586, 4804, 30834, 27727, 37766, 3882, 37540, 37757, 1542, 33326, 18929, 9171, 12050, 5567, 29204, 19069, 7280, 5220, 13675, 2411, 41412, 12484, 44618, 26661, 36137, 3717, 14263, 33130, 1358, 23283, 9430, 30870, 11401, 44227, 41656, 22969, 25980, 22984, 24483, 6438, 34898, 12316, 21745, 14967, 7750, 24293, 16243, 9370, 32309, 5945, 15816, 10479, 14230, 20407, 35325, 23675, 30687, 46680, 26741, 23388, 19655, 9431, 10317, 11423, 43670, 13546, 19037, 42175, 36543, 50216, 49894, 20180, 13304, 47570, 43753, 39600, 23742, 80, 6692, 1298, 23934, 46259, 33716, 15224, 30441, 12621, 1807, 13482, 41402, 8384, 24892, 27355, 20331, 32616, 26965, 32917, 37762, 41733, 31876, 2104, 19942, 7558, 40249, 24707, 2808, 7253, 10778, 12348, 10099, 28281, 25350, 27758, 15473, 2408, 17800, 6073, 2617, 24323, 28651, 9883, 11635, 25967, 27187, 16339, 33284, 6333, 13912, 36950, 14261, 19342, 15549, 47124, 31509, 33028, 13511, 37592, 41036, 7203, 26483, 34884, 2267, 38809, 34259, 49977, 12439, 1542, 33812, 5098, 7203, 16574, 15506, 14805, 18209, 32897, 23906, 10239, 37919, 34276, 49134, 15811, 25507, 2732, 46850, 47685, 45249, 7217, 4850, 17138, 27644, 11847, 3005, 22115, 17564, 13878, 46388, 157, 42569, 15332, 10451, 6044, 25087, 41065, 4258, 19466, 20935, 4516, 30929, 4270, 4035, 25800, 33696, 38225, 39258, 67, 34474, 24644, 26463, 21250, 35428, 31338, 2794, 33512, 38205, 15085])])\n",
      "-2.247023963928223\n",
      "True\n",
      "False\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "obs, rew, done, terminated, info = foo\n",
    "print(obs)\n",
    "print(rew)\n",
    "print(done)\n",
    "print(terminated)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids= action[\"input_ids\"]\n",
    "response_mask = action[\"response_mask\"]\n",
    "attention_mask = action[\"attention_mask\"]\n",
    "probs = action[\"probs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prompt_tokens = probs.shape[1]\n",
    "n_response_tokens = input_ids.shape[1] - n_prompt_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_response_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_align = env.reward_model(input_ids, attention_mask, response_mask)\n",
    "r_align = r_align.item()\n",
    "r_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "print(n_response_tokens)\n",
    "sft_output = generate_response(model, input_ids=input_ids, max_length=n_response_tokens, eos_token_id=tokenizer.eos_token_id)\n",
    "sft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_output[\"probs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.examples.rlhf.ppo_ft.rlhf_env import compute_approx_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = torch.tensor(probs[0])\n",
    "p_other = sft_output[\"probs\"]\n",
    "r_kl = compute_approx_kl(p, p_other)\n",
    "print(r_kl.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
